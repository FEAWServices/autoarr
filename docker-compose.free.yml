# Copyright (C) 2025 AutoArr Contributors
# This file is part of AutoArr (GPL-3.0 Licensed)

# ============================================================================
# AutoArr Free - Docker Compose Configuration
#
# This configuration runs the free version of AutoArr with Ollama for
# local LLM inference. No proprietary features or premium capabilities.
# ============================================================================

version: '3.8'

services:
  # AutoArr Free Application
  autoarr-free:
    build:
      context: .
      dockerfile: Dockerfile.free
    image: autoarr/autoarr-free:latest
    container_name: autoarr-free
    restart: unless-stopped

    # Resource limits (adjust based on your system)
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

    # Port mapping
    ports:
      - "${AUTOARR_PORT:-8000}:8000"

    # Environment variables
    environment:
      # Application
      - AUTOARR_VERSION=free
      - AUTOARR_ENV=production
      - LOG_LEVEL=${LOG_LEVEL:-info}

      # Ollama Configuration
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1:8b}

      # Claude API (disabled in free version)
      - CLAUDE_API_KEY=
      - CLAUDE_MODEL=

      # SABnzbd Configuration
      - SABNZBD_URL=${SABNZBD_URL:-http://sabnzbd:8080}
      - SABNZBD_API_KEY=${SABNZBD_API_KEY}
      - SABNZBD_ENABLED=${SABNZBD_ENABLED:-true}

      # Sonarr Configuration
      - SONARR_URL=${SONARR_URL:-http://sonarr:8989}
      - SONARR_API_KEY=${SONARR_API_KEY}
      - SONARR_ENABLED=${SONARR_ENABLED:-true}

      # Radarr Configuration
      - RADARR_URL=${RADARR_URL:-http://radarr:7878}
      - RADARR_API_KEY=${RADARR_API_KEY}
      - RADARR_ENABLED=${RADARR_ENABLED:-true}

      # Plex Configuration (optional)
      - PLEX_URL=${PLEX_URL}
      - PLEX_TOKEN=${PLEX_TOKEN}
      - PLEX_ENABLED=${PLEX_ENABLED:-false}

      # Database
      - DATABASE_URL=sqlite:////app/data/autoarr.db

      # Security
      - SECRET_KEY=${SECRET_KEY}

    # Volume mounts
    volumes:
      # Application data (SQLite DB, configuration)
      - autoarr-free-data:/app/data

      # Logs
      - autoarr-free-logs:/app/logs

      # Cache
      - autoarr-free-cache:/app/cache

      # Optional: Mount config file
      - ${CONFIG_DIR:-./config}:/app/config:ro

    # Networks
    networks:
      - autoarr-network

    # Dependencies
    depends_on:
      ollama:
        condition: service_healthy

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Ollama - Local LLM Server
  ollama:
    image: ollama/ollama:latest
    container_name: autoarr-ollama
    restart: unless-stopped

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G

    # Port mapping (optional, for direct access)
    ports:
      - "${OLLAMA_PORT:-11434}:11434"

    # Environment variables
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_MODELS=${OLLAMA_MODELS:-/root/.ollama/models}

    # Volume mounts
    volumes:
      # Model storage
      - ollama-models:/root/.ollama

    # Networks
    networks:
      - autoarr-network

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

# Networks
networks:
  autoarr-network:
    driver: bridge
    name: autoarr-free-network

# Volumes
volumes:
  # AutoArr data
  autoarr-free-data:
    driver: local
    name: autoarr-free-data

  # AutoArr logs
  autoarr-free-logs:
    driver: local
    name: autoarr-free-logs

  # AutoArr cache
  autoarr-free-cache:
    driver: local
    name: autoarr-free-cache

  # Ollama models
  ollama-models:
    driver: local
    name: autoarr-ollama-models
